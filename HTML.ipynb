{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1012 19:13:49.628803 19164 __init__.py:308] Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import Tokenizer, one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Embedding, TimeDistributed, RepeatVector, LSTM, concatenate , Input, Reshape, Dense, Flatten\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1012 19:13:49.920383 19164 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1012 19:13:49.952387 19164 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1012 19:13:49.963546 19164 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1012 19:13:50.000312 19164 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W1012 19:13:50.001257 19164 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W1012 19:13:50.083037 19164 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W1012 19:13:50.335397 19164 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W1012 19:13:51.101354 19164 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the images and preprocess them for inception-resnet\n",
    "images = []\n",
    "all_filenames = listdir('images/')\n",
    "all_filenames.sort()\n",
    "for filename in all_filenames:\n",
    "    images.append(img_to_array(load_img('images/'+filename, target_size=(299, 299))))\n",
    "images = np.array(images, dtype=float)\n",
    "images = preprocess_input(images)\n",
    "\n",
    "# Run the images through inception-resnet and extract the features without the classification layer\n",
    "IR2 = InceptionResNetV2(weights='imagenet', include_top=False)\n",
    "features = IR2.predict(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will cap each input sequence to 100 tokens\n",
    "max_caption_len = 100\n",
    "# Initialize the function that will create our vocabulary \n",
    "tokenizer = Tokenizer(filters='', split=\" \", lower=False)\n",
    "\n",
    "# Read a document and return a string\n",
    "def load_doc(filename):\n",
    "    file = open(filename, 'r')\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text\n",
    "\n",
    "# Load all the HTML files\n",
    "X = []\n",
    "all_filenames = listdir('html/')\n",
    "all_filenames.sort()\n",
    "for filename in all_filenames:\n",
    "    X.append(load_doc('html/'+filename))\n",
    "\n",
    "# Create the vocabulary from the html files\n",
    "tokenizer.fit_on_texts(X)\n",
    "\n",
    "# Add +1 to leave space for empty words\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "# Translate each word in text file to the matching vocabulary index\n",
    "sequences = tokenizer.texts_to_sequences(X)\n",
    "# The longest HTML file\n",
    "max_length = max(len(s) for s in sequences)\n",
    "\n",
    "# Intialize our final input to the model\n",
    "X, y, image_data = list(), list(), list()\n",
    "for img_no, seq in enumerate(sequences):\n",
    "    for i in range(1, len(seq)):\n",
    "        # Add the entire sequence to the input and only keep the next word for the output\n",
    "        in_seq, out_seq = seq[:i], seq[i]\n",
    "        # If the sentence is shorter than max_length, fill it up with empty words\n",
    "        in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
    "        # Map the output to one-hot encoding\n",
    "        out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
    "        # Add and image corresponding to the HTML file\n",
    "        image_data.append(features[img_no])\n",
    "        # Cut the input sentence to 100 tokens, and add it to the input data\n",
    "        X.append(in_seq[-100:])\n",
    "        y.append(out_seq)\n",
    "\n",
    "X, y, image_data = np.array(X), np.array(y), np.array(image_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1012 19:14:25.443329 19164 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the encoder\n",
    "image_features = Input(shape=(8, 8, 1536,))\n",
    "image_flat = Flatten()(image_features)\n",
    "image_flat = Dense(128, activation='relu')(image_flat)\n",
    "ir2_out = RepeatVector(max_caption_len)(image_flat)\n",
    "\n",
    "language_input = Input(shape=(max_caption_len,))\n",
    "language_model = Embedding(vocab_size, 200, input_length=max_caption_len)(language_input)\n",
    "language_model = LSTM(256, return_sequences=True)(language_model)\n",
    "language_model = LSTM(256, return_sequences=True)(language_model)\n",
    "language_model = TimeDistributed(Dense(128, activation='relu'))(language_model)\n",
    "\n",
    "# Create the decoder\n",
    "decoder = concatenate([ir2_out, language_model])\n",
    "decoder = LSTM(512, return_sequences=False)(decoder)\n",
    "decoder_output = Dense(vocab_size, activation='softmax')(decoder)\n",
    "\n",
    "# Compile the model\n",
    "model = Model(inputs=[image_features, language_input], outputs=decoder_output)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1012 19:14:25.611886 19164 deprecation.py:323] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/350\n",
      "2306/2306 [==============================] - 53s 23ms/step - loss: 5.9291\n",
      "Epoch 2/350\n",
      "2306/2306 [==============================] - 59s 26ms/step - loss: 5.7250\n",
      "Epoch 3/350\n",
      "2306/2306 [==============================] - 63s 27ms/step - loss: 5.7223\n",
      "Epoch 4/350\n",
      "2306/2306 [==============================] - 63s 27ms/step - loss: 5.7070\n",
      "Epoch 5/350\n",
      "2306/2306 [==============================] - 63s 28ms/step - loss: 5.6906\n",
      "Epoch 6/350\n",
      "2306/2306 [==============================] - 65s 28ms/step - loss: 5.6719\n",
      "Epoch 7/350\n",
      "2306/2306 [==============================] - 67s 29ms/step - loss: 5.6741\n",
      "Epoch 8/350\n",
      "2306/2306 [==============================] - 67s 29ms/step - loss: 5.6821\n",
      "Epoch 9/350\n",
      "2306/2306 [==============================] - 68s 29ms/step - loss: 5.6541\n",
      "Epoch 10/350\n",
      "2306/2306 [==============================] - 66s 29ms/step - loss: 5.6393\n",
      "Epoch 11/350\n",
      "2306/2306 [==============================] - 68s 29ms/step - loss: 5.6461\n",
      "Epoch 12/350\n",
      "2306/2306 [==============================] - 65s 28ms/step - loss: 5.6371\n",
      "Epoch 13/350\n",
      "2306/2306 [==============================] - 64s 28ms/step - loss: 5.6051\n",
      "Epoch 14/350\n",
      "2306/2306 [==============================] - 67s 29ms/step - loss: 5.6240\n",
      "Epoch 15/350\n",
      "2306/2306 [==============================] - 66s 29ms/step - loss: 5.5860\n",
      "Epoch 16/350\n",
      "2306/2306 [==============================] - 67s 29ms/step - loss: 5.5726\n",
      "Epoch 17/350\n",
      "2306/2306 [==============================] - 69s 30ms/step - loss: 5.5253\n",
      "Epoch 18/350\n",
      "2306/2306 [==============================] - 66s 29ms/step - loss: 5.5170\n",
      "Epoch 19/350\n",
      "2306/2306 [==============================] - 66s 29ms/step - loss: 5.4955\n",
      "Epoch 20/350\n",
      "2306/2306 [==============================] - 69s 30ms/step - loss: 5.4680\n",
      "Epoch 21/350\n",
      "2306/2306 [==============================] - 67s 29ms/step - loss: 5.4509\n",
      "Epoch 22/350\n",
      "2306/2306 [==============================] - 67s 29ms/step - loss: 5.4546\n",
      "Epoch 23/350\n",
      "2306/2306 [==============================] - 66s 29ms/step - loss: 5.4337\n",
      "Epoch 24/350\n",
      "2306/2306 [==============================] - 67s 29ms/step - loss: 5.4230\n",
      "Epoch 25/350\n",
      "2306/2306 [==============================] - 67s 29ms/step - loss: 5.3990\n",
      "Epoch 26/350\n",
      "2306/2306 [==============================] - 74s 32ms/step - loss: 5.3917\n",
      "Epoch 27/350\n",
      "2306/2306 [==============================] - 80s 35ms/step - loss: 5.4035\n",
      "Epoch 28/350\n",
      "2306/2306 [==============================] - 67s 29ms/step - loss: 5.4160\n",
      "Epoch 29/350\n",
      "2306/2306 [==============================] - 68s 29ms/step - loss: 5.4005\n",
      "Epoch 30/350\n",
      "2306/2306 [==============================] - 68s 29ms/step - loss: 5.3816\n",
      "Epoch 31/350\n",
      "2306/2306 [==============================] - 66s 29ms/step - loss: 5.3878\n",
      "Epoch 32/350\n",
      "2306/2306 [==============================] - 66s 29ms/step - loss: 5.3660\n",
      "Epoch 33/350\n",
      "2306/2306 [==============================] - 67s 29ms/step - loss: 5.3664\n",
      "Epoch 34/350\n",
      "2306/2306 [==============================] - 68s 29ms/step - loss: 5.3689\n",
      "Epoch 35/350\n",
      "2306/2306 [==============================] - 65s 28ms/step - loss: 5.3718\n",
      "Epoch 36/350\n",
      "2306/2306 [==============================] - 65s 28ms/step - loss: 5.3683\n",
      "Epoch 37/350\n",
      "2306/2306 [==============================] - 66s 29ms/step - loss: 5.3469\n",
      "Epoch 38/350\n",
      "2306/2306 [==============================] - 66s 28ms/step - loss: 5.3431\n",
      "Epoch 39/350\n",
      "2306/2306 [==============================] - 68s 29ms/step - loss: 5.3410\n",
      "Epoch 40/350\n",
      "2306/2306 [==============================] - 66s 28ms/step - loss: 5.3804\n",
      "Epoch 41/350\n",
      "2306/2306 [==============================] - 66s 29ms/step - loss: 5.3700\n",
      "Epoch 42/350\n",
      "2306/2306 [==============================] - 66s 29ms/step - loss: 5.3574\n",
      "Epoch 43/350\n",
      "2306/2306 [==============================] - 67s 29ms/step - loss: 5.3443\n",
      "Epoch 44/350\n",
      "2306/2306 [==============================] - 63s 27ms/step - loss: 5.3236\n",
      "Epoch 45/350\n",
      "2306/2306 [==============================] - 64s 28ms/step - loss: 5.3305\n",
      "Epoch 46/350\n",
      "2306/2306 [==============================] - 64s 28ms/step - loss: 5.3833\n",
      "Epoch 47/350\n",
      "2306/2306 [==============================] - 70s 31ms/step - loss: 5.4201\n",
      "Epoch 48/350\n",
      "2306/2306 [==============================] - 70s 30ms/step - loss: 5.3699\n",
      "Epoch 49/350\n",
      "2306/2306 [==============================] - 67s 29ms/step - loss: 5.3315\n",
      "Epoch 50/350\n",
      "2306/2306 [==============================] - 64s 28ms/step - loss: 5.3817\n",
      "Epoch 51/350\n",
      "2306/2306 [==============================] - 63s 27ms/step - loss: 5.3380\n",
      "Epoch 52/350\n",
      "2306/2306 [==============================] - 65s 28ms/step - loss: 5.3088\n",
      "Epoch 53/350\n",
      "2306/2306 [==============================] - 65s 28ms/step - loss: 5.2931\n",
      "Epoch 54/350\n",
      "2306/2306 [==============================] - 69s 30ms/step - loss: 5.3128\n",
      "Epoch 55/350\n",
      "2306/2306 [==============================] - 69s 30ms/step - loss: 5.3039\n",
      "Epoch 56/350\n",
      "2306/2306 [==============================] - 68s 30ms/step - loss: 5.3017\n",
      "Epoch 57/350\n",
      "2306/2306 [==============================] - 70s 30ms/step - loss: 5.3947\n",
      "Epoch 58/350\n",
      "2306/2306 [==============================] - 76s 33ms/step - loss: 5.3540\n",
      "Epoch 59/350\n",
      "2306/2306 [==============================] - 72s 31ms/step - loss: 5.3737\n",
      "Epoch 60/350\n",
      "2306/2306 [==============================] - 65s 28ms/step - loss: 5.3671\n",
      "Epoch 61/350\n",
      "2306/2306 [==============================] - 64s 28ms/step - loss: 5.3411\n",
      "Epoch 62/350\n",
      "2306/2306 [==============================] - 66s 28ms/step - loss: 5.3071\n",
      "Epoch 63/350\n",
      "2306/2306 [==============================] - 63s 27ms/step - loss: 5.3383\n",
      "Epoch 64/350\n",
      "2306/2306 [==============================] - 65s 28ms/step - loss: 5.3469\n",
      "Epoch 65/350\n",
      "2306/2306 [==============================] - 64s 28ms/step - loss: 5.3225\n",
      "Epoch 66/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 5.3460\n",
      "Epoch 67/350\n",
      "2306/2306 [==============================] - 64s 28ms/step - loss: 5.3707\n",
      "Epoch 68/350\n",
      "2306/2306 [==============================] - 66s 28ms/step - loss: 5.3477\n",
      "Epoch 69/350\n",
      "2306/2306 [==============================] - 64s 28ms/step - loss: 5.3386\n",
      "Epoch 70/350\n",
      "2306/2306 [==============================] - 66s 29ms/step - loss: 5.3652\n",
      "Epoch 71/350\n",
      "2306/2306 [==============================] - 65s 28ms/step - loss: 5.3630\n",
      "Epoch 72/350\n",
      "2306/2306 [==============================] - 64s 28ms/step - loss: 5.3566\n",
      "Epoch 73/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 5.3743\n",
      "Epoch 74/350\n",
      "2306/2306 [==============================] - 69s 30ms/step - loss: 5.3559\n",
      "Epoch 75/350\n",
      "2306/2306 [==============================] - 64s 28ms/step - loss: 5.3482\n",
      "Epoch 76/350\n",
      "2306/2306 [==============================] - 64s 28ms/step - loss: 5.3152\n",
      "Epoch 77/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 5.2880\n",
      "Epoch 78/350\n",
      "2306/2306 [==============================] - 64s 28ms/step - loss: 5.3162\n",
      "Epoch 79/350\n",
      "2306/2306 [==============================] - 63s 27ms/step - loss: 5.2772\n",
      "Epoch 80/350\n",
      "2306/2306 [==============================] - 64s 28ms/step - loss: 5.3192\n",
      "Epoch 81/350\n",
      "2306/2306 [==============================] - 65s 28ms/step - loss: 5.3583\n",
      "Epoch 82/350\n",
      "2306/2306 [==============================] - 64s 28ms/step - loss: 5.3145\n",
      "Epoch 83/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 5.3155\n",
      "Epoch 84/350\n",
      "2306/2306 [==============================] - 63s 27ms/step - loss: 5.2649\n",
      "Epoch 85/350\n",
      "2306/2306 [==============================] - 65s 28ms/step - loss: 5.3673\n",
      "Epoch 86/350\n",
      "2306/2306 [==============================] - 64s 28ms/step - loss: 5.3014\n",
      "Epoch 87/350\n",
      "2306/2306 [==============================] - 65s 28ms/step - loss: 5.3034\n",
      "Epoch 88/350\n",
      "2306/2306 [==============================] - 63s 27ms/step - loss: 5.2806\n",
      "Epoch 89/350\n",
      "2306/2306 [==============================] - 64s 28ms/step - loss: 5.3017\n",
      "Epoch 90/350\n",
      "2306/2306 [==============================] - 64s 28ms/step - loss: 5.2849\n",
      "Epoch 91/350\n",
      "2306/2306 [==============================] - 64s 28ms/step - loss: 5.3382\n",
      "Epoch 92/350\n",
      "2306/2306 [==============================] - 64s 28ms/step - loss: 5.3192\n",
      "Epoch 93/350\n",
      "2306/2306 [==============================] - 64s 28ms/step - loss: 5.2712\n",
      "Epoch 94/350\n",
      "2306/2306 [==============================] - 65s 28ms/step - loss: 5.2660\n",
      "Epoch 95/350\n",
      "2306/2306 [==============================] - 65s 28ms/step - loss: 5.2629\n",
      "Epoch 96/350\n",
      "2306/2306 [==============================] - 63s 27ms/step - loss: 5.2660\n",
      "Epoch 97/350\n",
      "2306/2306 [==============================] - 64s 28ms/step - loss: 5.2140\n",
      "Epoch 98/350\n",
      "2306/2306 [==============================] - 63s 27ms/step - loss: 5.2687\n",
      "Epoch 99/350\n",
      "2306/2306 [==============================] - 64s 28ms/step - loss: 5.2068\n",
      "Epoch 100/350\n",
      "2306/2306 [==============================] - 64s 28ms/step - loss: 5.2389\n",
      "Epoch 101/350\n",
      "2306/2306 [==============================] - 65s 28ms/step - loss: 5.2736\n",
      "Epoch 102/350\n",
      "2306/2306 [==============================] - 65s 28ms/step - loss: 5.2130\n",
      "Epoch 103/350\n",
      "2306/2306 [==============================] - 64s 28ms/step - loss: 5.2545\n",
      "Epoch 104/350\n",
      "2306/2306 [==============================] - 64s 28ms/step - loss: 5.2072\n",
      "Epoch 105/350\n",
      "2306/2306 [==============================] - 65s 28ms/step - loss: 5.2294\n",
      "Epoch 106/350\n",
      "2306/2306 [==============================] - 63s 27ms/step - loss: 5.3128\n",
      "Epoch 107/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 5.2992\n",
      "Epoch 108/350\n",
      "2306/2306 [==============================] - 64s 28ms/step - loss: 5.2948\n",
      "Epoch 109/350\n",
      "2306/2306 [==============================] - 64s 28ms/step - loss: 5.3113\n",
      "Epoch 110/350\n",
      "2306/2306 [==============================] - 66s 28ms/step - loss: 5.3363\n",
      "Epoch 111/350\n",
      "2306/2306 [==============================] - 63s 27ms/step - loss: 5.3109\n",
      "Epoch 112/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 5.2727\n",
      "Epoch 113/350\n",
      "2306/2306 [==============================] - 65s 28ms/step - loss: 5.2833\n",
      "Epoch 114/350\n",
      "2306/2306 [==============================] - 63s 27ms/step - loss: 5.3085\n",
      "Epoch 115/350\n",
      "2306/2306 [==============================] - 65s 28ms/step - loss: 5.2726\n",
      "Epoch 116/350\n",
      "2306/2306 [==============================] - 65s 28ms/step - loss: 5.2473\n",
      "Epoch 117/350\n",
      "2306/2306 [==============================] - 64s 28ms/step - loss: 5.2814\n",
      "Epoch 118/350\n",
      "2306/2306 [==============================] - 63s 27ms/step - loss: 5.2170\n",
      "Epoch 119/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 5.2549\n",
      "Epoch 120/350\n",
      "2306/2306 [==============================] - 64s 28ms/step - loss: 5.2153\n",
      "Epoch 121/350\n",
      "2306/2306 [==============================] - 63s 27ms/step - loss: 5.2303\n",
      "Epoch 122/350\n",
      "2306/2306 [==============================] - 64s 28ms/step - loss: 5.1979\n",
      "Epoch 123/350\n",
      "2306/2306 [==============================] - 63s 27ms/step - loss: 5.2117\n",
      "Epoch 124/350\n",
      "2306/2306 [==============================] - 63s 27ms/step - loss: 5.2213\n",
      "Epoch 125/350\n",
      "2306/2306 [==============================] - 64s 28ms/step - loss: 5.2113\n",
      "Epoch 126/350\n",
      "2306/2306 [==============================] - 65s 28ms/step - loss: 5.1928\n",
      "Epoch 127/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 5.1751\n",
      "Epoch 128/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 5.1696\n",
      "Epoch 129/350\n",
      "2306/2306 [==============================] - 66s 28ms/step - loss: 5.1644\n",
      "Epoch 130/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 5.1827\n",
      "Epoch 131/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 5.1493\n",
      "Epoch 132/350\n",
      "2306/2306 [==============================] - 61s 26ms/step - loss: 5.1860\n",
      "Epoch 133/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 5.1574\n",
      "Epoch 134/350\n",
      "2306/2306 [==============================] - 63s 27ms/step - loss: 5.1898\n",
      "Epoch 135/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 5.1572\n",
      "Epoch 136/350\n",
      "2306/2306 [==============================] - 63s 27ms/step - loss: 5.1788\n",
      "Epoch 137/350\n",
      "2306/2306 [==============================] - 61s 26ms/step - loss: 5.1569\n",
      "Epoch 138/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 5.1768\n",
      "Epoch 139/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 5.1601\n",
      "Epoch 140/350\n",
      "2306/2306 [==============================] - 60s 26ms/step - loss: 5.1843\n",
      "Epoch 141/350\n",
      "2306/2306 [==============================] - 60s 26ms/step - loss: 5.2018\n",
      "Epoch 142/350\n",
      "2306/2306 [==============================] - 61s 27ms/step - loss: 5.1697\n",
      "Epoch 143/350\n",
      "2306/2306 [==============================] - 61s 27ms/step - loss: 5.1645\n",
      "Epoch 144/350\n",
      "2306/2306 [==============================] - 63s 27ms/step - loss: 5.1482\n",
      "Epoch 145/350\n",
      "2306/2306 [==============================] - 63s 27ms/step - loss: 5.1131\n",
      "Epoch 146/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 5.1281\n",
      "Epoch 147/350\n",
      "2306/2306 [==============================] - 65s 28ms/step - loss: 5.1445\n",
      "Epoch 148/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 5.1343\n",
      "Epoch 149/350\n",
      "2306/2306 [==============================] - 63s 27ms/step - loss: 5.1530\n",
      "Epoch 150/350\n",
      "2306/2306 [==============================] - 67s 29ms/step - loss: 5.1646\n",
      "Epoch 151/350\n",
      "2306/2306 [==============================] - 63s 27ms/step - loss: 5.0903\n",
      "Epoch 152/350\n",
      "2306/2306 [==============================] - 64s 28ms/step - loss: 5.1093\n",
      "Epoch 153/350\n",
      "2306/2306 [==============================] - 66s 29ms/step - loss: 5.1338\n",
      "Epoch 154/350\n",
      "2306/2306 [==============================] - 68s 29ms/step - loss: 5.2434\n",
      "Epoch 155/350\n",
      "2306/2306 [==============================] - 65s 28ms/step - loss: 5.1654\n",
      "Epoch 156/350\n",
      "2306/2306 [==============================] - 64s 28ms/step - loss: 5.1479\n",
      "Epoch 157/350\n",
      "2306/2306 [==============================] - 64s 28ms/step - loss: 5.1423\n",
      "Epoch 158/350\n",
      "2306/2306 [==============================] - 61s 26ms/step - loss: 5.1304\n",
      "Epoch 159/350\n",
      "2306/2306 [==============================] - 63s 27ms/step - loss: 5.1781\n",
      "Epoch 160/350\n",
      "2306/2306 [==============================] - 65s 28ms/step - loss: 5.1576\n",
      "Epoch 161/350\n",
      "2306/2306 [==============================] - 65s 28ms/step - loss: 5.1433\n",
      "Epoch 162/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 5.2211\n",
      "Epoch 163/350\n",
      "2306/2306 [==============================] - 61s 26ms/step - loss: 5.1925\n",
      "Epoch 164/350\n",
      "2306/2306 [==============================] - 67s 29ms/step - loss: 5.1336\n",
      "Epoch 165/350\n",
      "2306/2306 [==============================] - 63s 27ms/step - loss: 5.1294\n",
      "Epoch 166/350\n",
      "2306/2306 [==============================] - 80s 35ms/step - loss: 5.1425\n",
      "Epoch 167/350\n",
      "2306/2306 [==============================] - 66s 29ms/step - loss: 5.1041\n",
      "Epoch 168/350\n",
      "2306/2306 [==============================] - 66s 28ms/step - loss: 5.1103\n",
      "Epoch 169/350\n",
      "2306/2306 [==============================] - 66s 29ms/step - loss: 5.0992\n",
      "Epoch 170/350\n",
      "2306/2306 [==============================] - 63s 27ms/step - loss: 5.0850\n",
      "Epoch 171/350\n",
      "2306/2306 [==============================] - 64s 28ms/step - loss: 5.1654\n",
      "Epoch 172/350\n",
      "2306/2306 [==============================] - 61s 27ms/step - loss: 5.1515\n",
      "Epoch 173/350\n",
      "2306/2306 [==============================] - 64s 28ms/step - loss: 5.1133\n",
      "Epoch 174/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 5.1016\n",
      "Epoch 175/350\n",
      "2306/2306 [==============================] - 63s 27ms/step - loss: 5.1311\n",
      "Epoch 176/350\n",
      "2306/2306 [==============================] - 64s 28ms/step - loss: 5.0896\n",
      "Epoch 177/350\n",
      "2306/2306 [==============================] - 63s 27ms/step - loss: 5.1256\n",
      "Epoch 178/350\n",
      "2306/2306 [==============================] - 63s 27ms/step - loss: 5.1432\n",
      "Epoch 179/350\n",
      "2306/2306 [==============================] - 64s 28ms/step - loss: 5.1021\n",
      "Epoch 180/350\n",
      "2306/2306 [==============================] - 63s 27ms/step - loss: 5.0831\n",
      "Epoch 181/350\n",
      "2306/2306 [==============================] - 64s 28ms/step - loss: 5.0657\n",
      "Epoch 182/350\n",
      "2306/2306 [==============================] - 65s 28ms/step - loss: 5.0602\n",
      "Epoch 183/350\n",
      "2306/2306 [==============================] - 63s 27ms/step - loss: 5.0338\n",
      "Epoch 184/350\n",
      "2306/2306 [==============================] - 63s 27ms/step - loss: 5.0665\n",
      "Epoch 185/350\n",
      "2306/2306 [==============================] - 63s 27ms/step - loss: 5.0644\n",
      "Epoch 186/350\n",
      "2306/2306 [==============================] - 61s 26ms/step - loss: 5.0345\n",
      "Epoch 187/350\n",
      "2306/2306 [==============================] - 61s 26ms/step - loss: 5.0619\n",
      "Epoch 188/350\n",
      "2306/2306 [==============================] - 61s 26ms/step - loss: 5.0411\n",
      "Epoch 189/350\n",
      "2306/2306 [==============================] - 61s 27ms/step - loss: 5.0322\n",
      "Epoch 190/350\n",
      "2306/2306 [==============================] - 60s 26ms/step - loss: 5.0273\n",
      "Epoch 191/350\n",
      "2306/2306 [==============================] - 60s 26ms/step - loss: 4.9830\n",
      "Epoch 192/350\n",
      "2306/2306 [==============================] - 61s 26ms/step - loss: 5.0235\n",
      "Epoch 193/350\n",
      "2306/2306 [==============================] - 61s 26ms/step - loss: 4.9926\n",
      "Epoch 194/350\n",
      "2306/2306 [==============================] - 61s 26ms/step - loss: 5.0006\n",
      "Epoch 195/350\n",
      "2306/2306 [==============================] - 60s 26ms/step - loss: 4.9158\n",
      "Epoch 196/350\n",
      "2306/2306 [==============================] - 61s 26ms/step - loss: 4.9131\n",
      "Epoch 197/350\n",
      "2306/2306 [==============================] - 61s 27ms/step - loss: 4.9109\n",
      "Epoch 198/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 4.8774\n",
      "Epoch 199/350\n",
      "2306/2306 [==============================] - 61s 27ms/step - loss: 4.9151\n",
      "Epoch 200/350\n",
      "2306/2306 [==============================] - 60s 26ms/step - loss: 4.9331\n",
      "Epoch 201/350\n",
      "2306/2306 [==============================] - 61s 27ms/step - loss: 4.9158\n",
      "Epoch 202/350\n",
      "2306/2306 [==============================] - 61s 26ms/step - loss: 4.9232\n",
      "Epoch 203/350\n",
      "2306/2306 [==============================] - 61s 26ms/step - loss: 4.8916\n",
      "Epoch 204/350\n",
      "2306/2306 [==============================] - 61s 27ms/step - loss: 4.9189\n",
      "Epoch 205/350\n",
      "2306/2306 [==============================] - 60s 26ms/step - loss: 4.9109\n",
      "Epoch 206/350\n",
      "2306/2306 [==============================] - 60s 26ms/step - loss: 4.8685\n",
      "Epoch 207/350\n",
      "2306/2306 [==============================] - 59s 26ms/step - loss: 4.8427\n",
      "Epoch 208/350\n",
      "2306/2306 [==============================] - 61s 26ms/step - loss: 4.8209\n",
      "Epoch 209/350\n",
      "2306/2306 [==============================] - 61s 26ms/step - loss: 4.8590\n",
      "Epoch 210/350\n",
      "2306/2306 [==============================] - 59s 25ms/step - loss: 4.8187\n",
      "Epoch 211/350\n",
      "2306/2306 [==============================] - 59s 25ms/step - loss: 4.8192\n",
      "Epoch 212/350\n",
      "2306/2306 [==============================] - 59s 25ms/step - loss: 4.8138\n",
      "Epoch 213/350\n",
      "2306/2306 [==============================] - 60s 26ms/step - loss: 4.8414\n",
      "Epoch 214/350\n",
      "2306/2306 [==============================] - 59s 25ms/step - loss: 4.7854\n",
      "Epoch 215/350\n",
      "2306/2306 [==============================] - 59s 26ms/step - loss: 4.7548\n",
      "Epoch 216/350\n",
      "2306/2306 [==============================] - 59s 26ms/step - loss: 4.7431\n",
      "Epoch 217/350\n",
      "2306/2306 [==============================] - 59s 26ms/step - loss: 4.7741\n",
      "Epoch 218/350\n",
      "2306/2306 [==============================] - 60s 26ms/step - loss: 4.7280\n",
      "Epoch 219/350\n",
      "2306/2306 [==============================] - 59s 26ms/step - loss: 4.6824\n",
      "Epoch 220/350\n",
      "2306/2306 [==============================] - 59s 26ms/step - loss: 4.7061\n",
      "Epoch 221/350\n",
      "2306/2306 [==============================] - 60s 26ms/step - loss: 4.7503\n",
      "Epoch 222/350\n",
      "2306/2306 [==============================] - 60s 26ms/step - loss: 4.7380\n",
      "Epoch 223/350\n",
      "2306/2306 [==============================] - 61s 26ms/step - loss: 4.6740\n",
      "Epoch 224/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 4.6647\n",
      "Epoch 225/350\n",
      "2306/2306 [==============================] - 60s 26ms/step - loss: 4.6712\n",
      "Epoch 226/350\n",
      "2306/2306 [==============================] - 61s 26ms/step - loss: 4.6433\n",
      "Epoch 227/350\n",
      "2306/2306 [==============================] - 60s 26ms/step - loss: 4.5949\n",
      "Epoch 228/350\n",
      "2306/2306 [==============================] - 61s 26ms/step - loss: 4.5706\n",
      "Epoch 229/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 4.5767\n",
      "Epoch 230/350\n",
      "2306/2306 [==============================] - 60s 26ms/step - loss: 4.5482\n",
      "Epoch 231/350\n",
      "2306/2306 [==============================] - 60s 26ms/step - loss: 4.5426\n",
      "Epoch 232/350\n",
      "2306/2306 [==============================] - 64s 28ms/step - loss: 4.5333\n",
      "Epoch 233/350\n",
      "2306/2306 [==============================] - 64s 28ms/step - loss: 4.5659\n",
      "Epoch 234/350\n",
      "2306/2306 [==============================] - 66s 29ms/step - loss: 4.5407\n",
      "Epoch 235/350\n",
      "2306/2306 [==============================] - 65s 28ms/step - loss: 4.4816\n",
      "Epoch 236/350\n",
      "2306/2306 [==============================] - 65s 28ms/step - loss: 4.4410\n",
      "Epoch 237/350\n",
      "2306/2306 [==============================] - 63s 27ms/step - loss: 4.4717\n",
      "Epoch 238/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 4.4101\n",
      "Epoch 239/350\n",
      "2306/2306 [==============================] - 61s 26ms/step - loss: 4.4146\n",
      "Epoch 240/350\n",
      "2306/2306 [==============================] - 61s 26ms/step - loss: 4.3931\n",
      "Epoch 241/350\n",
      "2306/2306 [==============================] - 61s 26ms/step - loss: 4.3590\n",
      "Epoch 242/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 4.3398\n",
      "Epoch 243/350\n",
      "2306/2306 [==============================] - 63s 27ms/step - loss: 4.2646\n",
      "Epoch 244/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 4.2855\n",
      "Epoch 245/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 4.2900\n",
      "Epoch 246/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 4.2308\n",
      "Epoch 247/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 4.2683\n",
      "Epoch 248/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 4.2550\n",
      "Epoch 249/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 4.2368\n",
      "Epoch 250/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 4.1508\n",
      "Epoch 251/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 4.2146\n",
      "Epoch 252/350\n",
      "2306/2306 [==============================] - 61s 26ms/step - loss: 4.1348\n",
      "Epoch 253/350\n",
      "2306/2306 [==============================] - 64s 28ms/step - loss: 4.1632\n",
      "Epoch 254/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 4.1884\n",
      "Epoch 255/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 4.0777\n",
      "Epoch 256/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 4.0289\n",
      "Epoch 257/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 3.9909\n",
      "Epoch 258/350\n",
      "2306/2306 [==============================] - 64s 28ms/step - loss: 3.9146\n",
      "Epoch 259/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 3.8650\n",
      "Epoch 260/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 3.8773\n",
      "Epoch 261/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 3.8243\n",
      "Epoch 262/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 3.7938\n",
      "Epoch 263/350\n",
      "2306/2306 [==============================] - 64s 28ms/step - loss: 3.7359\n",
      "Epoch 264/350\n",
      "2306/2306 [==============================] - 61s 27ms/step - loss: 3.6805\n",
      "Epoch 265/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 3.6558\n",
      "Epoch 266/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 3.6699\n",
      "Epoch 267/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 3.5750\n",
      "Epoch 268/350\n",
      "2306/2306 [==============================] - 64s 28ms/step - loss: 3.5410\n",
      "Epoch 269/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 3.4613\n",
      "Epoch 270/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 3.4292\n",
      "Epoch 271/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 3.4046\n",
      "Epoch 272/350\n",
      "2306/2306 [==============================] - 61s 26ms/step - loss: 3.4196\n",
      "Epoch 273/350\n",
      "2306/2306 [==============================] - 64s 28ms/step - loss: 3.3781\n",
      "Epoch 274/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 3.3211\n",
      "Epoch 275/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 3.2246\n",
      "Epoch 276/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 3.2695\n",
      "Epoch 277/350\n",
      "2306/2306 [==============================] - 63s 27ms/step - loss: 3.2174\n",
      "Epoch 278/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 3.1268\n",
      "Epoch 279/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 3.1048\n",
      "Epoch 280/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 3.0413\n",
      "Epoch 281/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 3.0506\n",
      "Epoch 282/350\n",
      "2306/2306 [==============================] - 61s 26ms/step - loss: 2.9829\n",
      "Epoch 283/350\n",
      "2306/2306 [==============================] - 65s 28ms/step - loss: 2.9294\n",
      "Epoch 284/350\n",
      "2306/2306 [==============================] - 63s 27ms/step - loss: 2.9201\n",
      "Epoch 285/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 2.8170\n",
      "Epoch 286/350\n",
      "2306/2306 [==============================] - 61s 26ms/step - loss: 2.9218\n",
      "Epoch 287/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 2.8321\n",
      "Epoch 288/350\n",
      "2306/2306 [==============================] - 67s 29ms/step - loss: 2.8198\n",
      "Epoch 289/350\n",
      "2306/2306 [==============================] - 63s 27ms/step - loss: 2.6860\n",
      "Epoch 290/350\n",
      "2306/2306 [==============================] - 63s 27ms/step - loss: 2.7108\n",
      "Epoch 291/350\n",
      "2306/2306 [==============================] - 61s 26ms/step - loss: 2.6480\n",
      "Epoch 292/350\n",
      "2306/2306 [==============================] - 61s 26ms/step - loss: 2.5926\n",
      "Epoch 293/350\n",
      "2306/2306 [==============================] - 64s 28ms/step - loss: 2.5776\n",
      "Epoch 294/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 2.5178\n",
      "Epoch 295/350\n",
      "2306/2306 [==============================] - 61s 26ms/step - loss: 2.4908\n",
      "Epoch 296/350\n",
      "2306/2306 [==============================] - 60s 26ms/step - loss: 2.4342\n",
      "Epoch 297/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 2.4219\n",
      "Epoch 298/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 2.4191\n",
      "Epoch 299/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 2.5193\n",
      "Epoch 300/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 2.4227\n",
      "Epoch 301/350\n",
      "2306/2306 [==============================] - 63s 27ms/step - loss: 2.5617\n",
      "Epoch 302/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 2.5493\n",
      "Epoch 303/350\n",
      "2306/2306 [==============================] - 64s 28ms/step - loss: 2.3682\n",
      "Epoch 304/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 2.3536\n",
      "Epoch 305/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 2.4011\n",
      "Epoch 306/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 2.2944\n",
      "Epoch 307/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 2.1588\n",
      "Epoch 308/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 2.0949\n",
      "Epoch 309/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 2.0283\n",
      "Epoch 310/350\n",
      "2306/2306 [==============================] - 63s 27ms/step - loss: 2.0580\n",
      "Epoch 311/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 1.9278\n",
      "Epoch 312/350\n",
      "2306/2306 [==============================] - 61s 26ms/step - loss: 1.9705\n",
      "Epoch 313/350\n",
      "2306/2306 [==============================] - 64s 28ms/step - loss: 1.8620\n",
      "Epoch 314/350\n",
      "2306/2306 [==============================] - 63s 27ms/step - loss: 1.7680\n",
      "Epoch 315/350\n",
      "2306/2306 [==============================] - 63s 27ms/step - loss: 1.7370\n",
      "Epoch 316/350\n",
      "2306/2306 [==============================] - 63s 27ms/step - loss: 1.6972\n",
      "Epoch 317/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 1.7142\n",
      "Epoch 318/350\n",
      "2306/2306 [==============================] - 63s 27ms/step - loss: 1.6812\n",
      "Epoch 319/350\n",
      "2306/2306 [==============================] - 63s 27ms/step - loss: 1.6294\n",
      "Epoch 320/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 1.6106\n",
      "Epoch 321/350\n",
      "2306/2306 [==============================] - 61s 27ms/step - loss: 1.6096\n",
      "Epoch 322/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 1.6165\n",
      "Epoch 323/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 1.5653\n",
      "Epoch 324/350\n",
      "2306/2306 [==============================] - 61s 26ms/step - loss: 1.5657\n",
      "Epoch 325/350\n",
      "2306/2306 [==============================] - 61s 27ms/step - loss: 1.3418\n",
      "Epoch 326/350\n",
      "2306/2306 [==============================] - 61s 27ms/step - loss: 1.2923\n",
      "Epoch 327/350\n",
      "2306/2306 [==============================] - 61s 26ms/step - loss: 1.2239\n",
      "Epoch 328/350\n",
      "2306/2306 [==============================] - 63s 27ms/step - loss: 1.1888\n",
      "Epoch 329/350\n",
      "2306/2306 [==============================] - 61s 27ms/step - loss: 1.2439\n",
      "Epoch 330/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 1.1257\n",
      "Epoch 331/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 1.1295\n",
      "Epoch 332/350\n",
      "2306/2306 [==============================] - 61s 27ms/step - loss: 1.0660\n",
      "Epoch 333/350\n",
      "2306/2306 [==============================] - 64s 28ms/step - loss: 1.0185\n",
      "Epoch 334/350\n",
      "2306/2306 [==============================] - 63s 27ms/step - loss: 1.0037\n",
      "Epoch 335/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 0.9555\n",
      "Epoch 336/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 0.9023\n",
      "Epoch 337/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 0.8771\n",
      "Epoch 338/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 0.8359\n",
      "Epoch 339/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 0.8001\n",
      "Epoch 340/350\n",
      "2306/2306 [==============================] - 64s 28ms/step - loss: 0.7749\n",
      "Epoch 341/350\n",
      "2306/2306 [==============================] - 61s 27ms/step - loss: 0.7453\n",
      "Epoch 342/350\n",
      "2306/2306 [==============================] - 64s 28ms/step - loss: 0.7247\n",
      "Epoch 343/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 0.6812\n",
      "Epoch 344/350\n",
      "2306/2306 [==============================] - 63s 27ms/step - loss: 0.7717\n",
      "Epoch 345/350\n",
      "2306/2306 [==============================] - 61s 26ms/step - loss: 0.6640\n",
      "Epoch 346/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 0.6284\n",
      "Epoch 347/350\n",
      "2306/2306 [==============================] - 64s 28ms/step - loss: 0.6186\n",
      "Epoch 348/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 0.5511\n",
      "Epoch 349/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 0.5692\n",
      "Epoch 350/350\n",
      "2306/2306 [==============================] - 62s 27ms/step - loss: 0.5596\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ad1eb47da0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the neural network\n",
    "model.fit([image_data, X], y, batch_size=64, shuffle=False, epochs=350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map an integer to a word\n",
    "def word_for_id(integer, tokenizer):\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == integer:\n",
    "            return word\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a description for an image\n",
    "def generate_desc(model, tokenizer, photo, max_length):\n",
    "    # seed the generation process\n",
    "    in_text = 'START'\n",
    "    # iterate over the whole length of the sequence\n",
    "    for i in range(900):\n",
    "        # integer encode input sequence\n",
    "        sequence = tokenizer.texts_to_sequences([in_text])[0][-100:]\n",
    "        # pad input\n",
    "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
    "        # predict next word\n",
    "        yhat = model.predict([photo,sequence], verbose=0)\n",
    "        # convert probability to integer\n",
    "        yhat = np.argmax(yhat)\n",
    "        # map integer to word\n",
    "        word = word_for_id(yhat, tokenizer)\n",
    "        # stop if we cannot map the word\n",
    "        if word is None:\n",
    "            break\n",
    "        # append as input for generating the next word\n",
    "        in_text += ' ' + word\n",
    "        # Print the prediction\n",
    "        print(' ' + word, end='')\n",
    "        # stop if we predict the end of the sequence\n",
    "        if word == 'END':\n",
    "            break\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " <!DOCTYPE html>\n",
      "<html lang=\"en\" dir=\"ltr\">\n",
      "<head>\n",
      "<title>Basic 87</title>\n",
      "<meta charset=\"iso-8859-1\">\n",
      "<link rel=\"stylesheet\" href=\"styles/layout.css\" type=\"text/css\">\n",
      "<!--[if lt IE 9]><script src=\"scripts/html5shiv.js\"></script><![endif]-->\n",
      "</head>\n",
      "<body>\n",
      "<div class=\"wrapper row1\">\n",
      " <header id=\"header\" class=\"clear\">\n",
      " <div id=\"hgroup\">\n",
      " <h1><a href=\"#\">Basic 87</a></h1>\n",
      " <h2>Free HTML5 Website Template</h2>\n",
      " </div>\n",
      " <nav>\n",
      " <ul>\n",
      " <li><a href=\"#\">Text Link</a></li>\n",
      " <li><a href=\"#\">Text Link</a></li>\n",
      " <li><a href=\"#\">Text Link</a></li>\n",
      " <li><a href=\"#\">Text Link</a></li>\n",
      " <li><a href=\"#\">Text Link</a></li>\n",
      " <li><a href=\"#\">Text Link</a></li>\n",
      " <li><a href=\"#\">Text Link</a></li>\n",
      " <li><a href=\"#\">Text Link</a></li>\n",
      " <li><a href=\"#\">Text Link</a></li>\n",
      " <li><a href=\"#\">Text Link</a></li>\n",
      " <li><a href=\"#\">Text Link</a></li>\n",
      " <li><a href=\"#\">Text Link</a></li>\n",
      " <li><a href=\"#\">Text Link</a></li>\n",
      " <li><a href=\"#\">Text Link</a></li>\n",
      " <li><a href=\"#\">Text Link</a></li>\n",
      " <li><a href=\"#\">Text Link</a></li>\n",
      " <li><a href=\"#\">Text Link</a></li>\n",
      " <li><a href=\"#\">Text Link</a></li>\n",
      " <li><a href=\"#\">Text Link</a></li>\n",
      " <li><a href=\"#\">Text Link</a></li>\n",
      " <li><a href=\"#\">Text Link</a></li>\n",
      " <li><a href=\"#\">Text Link</a></li>\n",
      " <li><a href=\"#\">Text Link</a></li>\n",
      " <li><a href=\"#\">Text urna <!-- content -->\n",
      "<div class=\"wrapper row2\">\n",
      " <div id=\"container\" class=\"clear\">\n",
      " <!-- content -->\n",
      "<div class=\"wrapper row2\">\n",
      " <div id=\"container\" class=\"clear\">\n",
      " vitae One Quarter -->\n",
      " <section id=\"latest\" class=\"clear\">\n",
      " urnaretra nulla aenean elit convallis urna neque height=\"315\" vitae <figcaption>Image Caption nulla Here</figcaption>\n",
      " </figure>\n",
      " class=\"more\"><a </article>\n",
      " <article egestibulum width=\"215\" height=\"315\" vitae <figcaption>Image Caption nulla Here</figcaption>\n",
      " </figure>\n",
      " class=\"more\"><a </article>\n",
      " <article egestibulum width=\"215\" height=\"315\" vitae <figcaption>Image Caption aenean elit intesque sed. Facilispede estibulum nulla orna nisl convallis augue estas aenean elit intesque sed. Facilispede estibulum nulla orna nisl convallis augue estas aenean elit intesque sed. Facilispede estibulum nulla orna nisl aenean elit aliquat vitae <figcaption>Image Here</figcaption>\n",
      " vitae <figcaption>\n",
      " <h2>Indonectetus tincidunt. Namjusto cras quis estas aenean aliquat non tincidunt. Namjusto cras quis estas aenean aliquat non tincidunt. Namjusto Caption aliquat alt=\"\">\n",
      " <figcaption>Image Caption Here</figcaption>\n",
      " vitae <figcaption>\n",
      " <h2>Indonectetus facilis leo nibh</h2>\n",
      " <p>This is is &raquo;</a></footer>\n",
      " </figcaption>\n",
      " </figure>\n",
      " </article>\n",
      " </li>\n",
      " <ul>\n",
      " </div>\n",
      " <!-- facilis leo nibh</h2>\n",
      " <p>This a </li>\n",
      " <ul>\n",
      " row3\">\n",
      " </ul>\n",
      " <footer <!-- One facilis leo nibh</h2>\n",
      " <p>This href=\"#\">Read More &raquo;</a></footer>\n",
      " </figcaption>\n",
      " </figure>\n",
      " </article>\n",
      " </li>\n",
      " <ul>\n",
      " <div estas content -->\n",
      " <div id=\"latest\" content Templates</a>. a </li>\n",
      " <ul>\n",
      " <li>\n",
      " <article class=\"clear\">\n",
      " <figure><img src=\"images/demo/180x150.gif\" alt=\"\">\n",
      " <figcaption>\n",
      " <h2>Indonectetus facilis leo nibh</h2>\n",
      " <p>This is href=\"#\">Read More &raquo;</a></footer>\n",
      " </figcaption>\n",
      " </figure>\n",
      " </article>\n",
      " </li>\n",
      " </ul>\n",
      " <li>\n",
      " </div>\n",
      " <h2>Indonectetus lastbox\">\n",
      " <figure><img src=\"images/demo/215x315.gif\" estibulum class=\"clear\">\n",
      " <!-- src=\"images/demo/180x150.gif\" leo <figcaption>\n",
      " <h2>Indonectetus <h2>Indonectetus facilis -->\n",
      " <section id=\"shout\">\n",
      " facilis -->\n",
      " <li><a href=\"#\">Free Webdesign convallis <li><a convallis <li><a href=\"#\">Free Website href=\"#\">Free justo href=\"#\">Free Website convallis <li><a href=\"#\">Free urna neque Caption aenean quis convallis quis Templates</a></li>\n",
      " nulla href=\"#\">Free nulla orci Templates</a></li>\n",
      " nulla orna nisl aliquat Themes</a></li>\n",
      " quis orci nulla nulla Caption nulla aenean quis orci laoremut nulla Caption lastbox\">\n",
      " vitae doloreet Quarter -->\n",
      " <section id=\"shout\">\n",
      " Quarter leo nibh</h2>\n",
      " <p>This href=\"#\">Read More &raquo;</a></footer>\n",
      " </article>\n",
      " <h2>Indonectetus facilis leo </article>\n",
      " <h2>Indonectetus facilis leo nibh</h2>\n",
      " by All Rights Reserved is <a <!-- id=\"shout\">\n",
      " / content -->\n",
      " <li row3\">\n",
      " row3\">\n",
      " row3\">\n",
      " <div id=\"homepage\">\n",
      " vitae doloreet condimentumst.</p>\n",
      " leo nibh</h2>\n",
      " <p>This a </figcaption>\n",
      " </figure>\n",
      " </article>\n",
      " <figcaption>\n",
      " <p>Vestibulumaccumsan facilis -->\n",
      " nulla lastbox\">\n",
      " Quarter -->\n",
      " <ul>\n",
      " class=\"last\">\n",
      " clear\">\n",
      " class=\"clear\">\n",
      " lastbox\">\n",
      " main <section orna content -->\n",
      " nulla Templates</a></li>\n",
      " class=\"clear\">\n",
      " urnaretra /nav -->\n",
      " <div id=\"services\" content body nibh</h2>\n",
      " <p>This is template <a read -->\n",
      " HTML5 Templates</a></p>\n",
      " -->\n",
      " <li><a id=\"right_column\">\n",
      " Webdesign Templates</a></li>\n",
      " <li><a href=\"#\">Free FireWorks Templates</a></li>\n",
      " <li><a href=\"#\">Free Webdesign Templates</a></li>\n",
      " <li><a href=\"#\">Free href=\"#\">Free href=\"#\">Free FireWorks orci Templates</a></li>\n",
      " <li row3\">\n",
      " Website href=\"#\">Free Webdesign href=\"#\">Free urna vitae doloreet nulla Themes</a></li>\n",
      " <li><a href=\"#\">Free Website href=\"#\">Free urna vitae condimentumst.</p>\n",
      " vitae doloreet condimentumst.</p>\n",
      " -->\n",
      " <li><a href=\"#\">Free velit aliquat non <figcaption>Image Here</figcaption>\n",
      " </figure>\n",
      " </article>\n",
      " </section>\n",
      " </figure>\n",
      " clear\">\n",
      " <ul>\n",
      " <footer clear\">\n",
      " <ul>\n",
      " href=\"#\">Free 5 aliquat </section>\n",
      " vitae main content leo -->\n",
      " </div>\n",
      "</div>\n",
      "<!-- Footer </div>\n",
      " <!-- <p>Vestibulumaccumsan egestibulum facilis -->\n",
      " </div>\n",
      "</div>\n",
      "<!-- id=\"latest\" content body -->\n",
      " <!-- Footer -->\n",
      " content body </footer>\n",
      "</div>\n",
      "</body>\n",
      "</html> END"
     ]
    }
   ],
   "source": [
    "# Load and image, preprocess it for IR2, extract features and generate the HTML\n",
    "test_image = img_to_array(load_img('images/87.jpg', target_size=(299, 299)))\n",
    "test_image = np.array(test_image, dtype=float)\n",
    "test_image = preprocess_input(test_image)\n",
    "test_features = IR2.predict(np.array([test_image]))\n",
    "generate_desc(model, tokenizer, np.array(test_features), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
